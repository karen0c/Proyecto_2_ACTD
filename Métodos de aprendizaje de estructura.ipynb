{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd5bd313",
   "metadata": {},
   "source": [
    "## Proy 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e25119d",
   "metadata": {},
   "source": [
    "Importación y transformación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6db76a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columnas = [\"age\",\"sex\",\"cp\",\"trestbps\",\"chol\",\"fbs\",\"restecg\",\"thalach\",\"exang\",\"oldpeak\",\"slope\",\"ca\",\"thal\",\"num\"]\n",
    "datos_iniciales = pd.read_csv('https://raw.githubusercontent.com/karen0c/Proyecto_1_ACTD/main/processed.cleveland.data',header=None, names=columnas, na_values=\"?\")\n",
    "\n",
    "datos_iniciales = datos_iniciales.dropna().reset_index(drop=True) #elimina filas con valores faltantes\n",
    "#print(datos_iniciales.head())\n",
    "#print(datos_iniciales.tail())\n",
    "\n",
    "# crear unos nuevos datos donde guardaremos la información con los datos discretizados\n",
    "datos = datos_iniciales\n",
    "\n",
    "for i in range(0,297):\n",
    "  if datos_iniciales.loc[i, 'age'] <= 40:\n",
    "    datos.loc[i, 'age'] = 1\n",
    "  elif datos_iniciales.loc[i, 'age'] > 40 and datos_iniciales.loc[i, 'age'] <= 50:\n",
    "    datos.loc[i, 'age'] = 2\n",
    "  elif datos_iniciales.loc[i, 'age'] > 50 and datos_iniciales.loc[i, 'age'] <= 60:\n",
    "    datos.loc[i, 'age'] = 3\n",
    "  else:\n",
    "    datos.loc[i, 'age'] = 4\n",
    "\n",
    "for i in range(0,297):\n",
    "  if datos_iniciales.loc[i, \"trestbps\"] <= 120:\n",
    "    datos.loc[i, \"trestbps\"] = 1\n",
    "  elif datos_iniciales.loc[i, \"trestbps\"] > 120 and datos_iniciales.loc[i, \"trestbps\"] <= 139:\n",
    "    datos.loc[i, \"trestbps\"] = 2\n",
    "  elif datos_iniciales.loc[i, \"trestbps\"] >= 140 and datos_iniciales.loc[i, \"trestbps\"] <= 159:\n",
    "    datos.loc[i, \"trestbps\"] = 3\n",
    "  elif datos_iniciales.loc[i, \"trestbps\"] >= 160 and datos_iniciales.loc[i, \"trestbps\"] <= 179:\n",
    "    datos.loc[i, \"trestbps\"] = 4\n",
    "  else:\n",
    "    datos.loc[i, \"trestbps\"] = 5\n",
    "    \n",
    "for i in range(0,297):\n",
    "  if datos_iniciales.loc[i, \"chol\"] <= 200:\n",
    "    datos.loc[i, \"chol\"] = 1\n",
    "  elif datos_iniciales.loc[i, \"chol\"] > 200 and datos_iniciales.loc[i, \"chol\"] < 240:\n",
    "    datos.loc[i, \"chol\"] = 2\n",
    "  else:\n",
    "    datos.loc[i, \"chol\"] = 3\n",
    "    \n",
    "for i in range(0,297):\n",
    "  if datos_iniciales.loc[i, \"thalach\"] <= 120:\n",
    "    datos.loc[i, \"thalach\"] = 1\n",
    "  elif datos_iniciales.loc[i, \"thalach\"] > 120 and datos_iniciales.loc[i, \"thalach\"] <= 140:\n",
    "    datos.loc[i, \"thalach\"] = 2\n",
    "  elif datos_iniciales.loc[i, \"thalach\"] > 140 and datos_iniciales.loc[i, \"thalach\"] < 160:\n",
    "    datos.loc[i, \"thalach\"] = 3\n",
    "  else:\n",
    "    datos.loc[i, \"thalach\"] = 4\n",
    "    \n",
    "for i in range(0,297):\n",
    "  if datos_iniciales.loc[i, \"oldpeak\"] <= 1:\n",
    "    datos.loc[i, \"oldpeak\"] = 1\n",
    "  elif datos_iniciales.loc[i, \"oldpeak\"] > 1 and datos_iniciales.loc[i, \"oldpeak\"] <= 2:\n",
    "    datos.loc[i, \"oldpeak\"] = 2\n",
    "  else:\n",
    "    datos.loc[i, \"oldpeak\"] = 3\n",
    "    \n",
    "for i in datos_iniciales.index:\n",
    "  if datos_iniciales.loc[i, \"num\"] == 0:\n",
    "    datos.loc[i, \"num\"] = 0\n",
    "  else:\n",
    "    datos.loc[i, \"num\"] = 1\n",
    "\n",
    "#USAR SOLO EL 80% DE LOS DATOS, PARA QUE SIRVAN COMO ENTRENAMIENTO, LO DEMÁS SE USARÁ COMO TEST\n",
    "sep = int(0.8*len(datos))\n",
    "datos_train = datos[:sep]\n",
    "#print(datos_train.head(10))\n",
    "#print(datos_train.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9361b3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237\n"
     ]
    }
   ],
   "source": [
    "print(sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "96bfeb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_prueba = datos[sep:]\n",
    "#print(datos_prueba.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de57558",
   "metadata": {},
   "source": [
    "Estime la estructura del modelo usando el método por restricciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "18e78869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39bc3ca81f844518349d4d78ac1c6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['thal', 'num', 'exang', 'cp', 'oldpeak', 'slope', 'ca', 'age', 'trestbps', 'restecg', 'sex']\n",
      "[('thal', 'num'), ('exang', 'cp'), ('slope', 'oldpeak'), ('age', 'ca'), ('restecg', 'trestbps'), ('sex', 'thal')]\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.estimators import PC\n",
    "est = PC(data=datos_train)\n",
    "\n",
    "estimated_model = est.estimate(variant=\"stable\", max_cond_vars=3)\n",
    "print(estimated_model)\n",
    "print(estimated_model.nodes())\n",
    "print(estimated_model.edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12147d69",
   "metadata": {},
   "source": [
    "Se convierte el objeto DAG obtenido con el anterior procedimiento a una red bayesiana y se usa el estimador de máxima verosimilitud para estimar los parámetros de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a780e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "\n",
    "estimated_model = BayesianNetwork(estimated_model)\n",
    "estimated_model.fit(data=datos_prueba, estimator = MaximumLikelihoodEstimator) \n",
    "#for i in estimated_model.nodes():\n",
    " #   print(estimated_model.get_cpds(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51a2965",
   "metadata": {},
   "source": [
    "### Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b8795326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "from pgmpy.inference import VariableElimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "67030041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una lista vacía para contener las variables del modelo\n",
    "variables_modelo = []\n",
    "\n",
    "# Recorrer cada variable del modelo y agregarla a la lista si está presente en la base de datos original\n",
    "for nodo in estimated_model.nodes():\n",
    "    if nodo in datos_prueba.columns:\n",
    "        variables_modelo.append(datos_prueba[nodo])\n",
    "\n",
    "# Concatenar todas las variables en una sola base de datos\n",
    "nueva_base = pd.concat(variables_modelo, axis=1)\n",
    "#print(nueva_base.tail())\n",
    "#print(len(nueva_base))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fd2a5b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversión de respuesta de datos de prueba a una variable binaria\n",
    "# 0-> no hay enfermedad; 1-> hay presencia de enfermedad\n",
    "bin_test = []\n",
    "\n",
    "for i in nueva_base.index:\n",
    "  if nueva_base.loc[i, \"num\"] == 0:\n",
    "    bin_test.append(0)      \n",
    "  else:\n",
    "    bin_test.append(1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cfb79a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(bin_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0df2532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un objeto de inferencia basado en el modelo entrenado\n",
    "infer = VariableElimination(estimated_model)\n",
    "bin_modelo = []\n",
    "# Calcular las predicciones para cada fila en los datos de prueba\n",
    "for i in (nueva_base.index):\n",
    "    evidence = nueva_base.loc[i].to_dict()\n",
    "    evidence.pop('num', None)  # Elimina la clave 'num' del diccionario si está presente\n",
    "    prediccion = infer.query(['num'], evidence=evidence)\n",
    "    #print(f'Predicción para la fila {i}: {prediccion.values}')\n",
    "\n",
    "    \n",
    "    posicion = -1\n",
    "    probabilidad = -1\n",
    "    for j in range(0,2):\n",
    "        if prediccion.values[estimated_model.get_cpds(\"num\").state_names[\"num\"].index(j)]>probabilidad:\n",
    "            probabilidad = prediccion.values[estimated_model.get_cpds(\"num\").state_names[\"num\"].index(j)]\n",
    "            posicion = j\n",
    "            \n",
    "    if posicion == 0:\n",
    "        bin_modelo.append(0)\n",
    "    else:\n",
    "        bin_modelo.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2cc4b060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bin_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "70535d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "verd_positivo = 0\n",
    "verd_negativo = 0\n",
    "falso_positivo = 0\n",
    "falso_negativo = 0\n",
    "\n",
    "#contar el número de verdaderos positivos y negativos            \n",
    "for i in range(len(nueva_base)):\n",
    "    if bin_test[i]==bin_modelo[i]:\n",
    "        if bin_modelo[i]==0:\n",
    "            verd_positivo = verd_positivo+1\n",
    "        else:\n",
    "            verd_negativo = verd_negativo+1\n",
    "    else:\n",
    "        if bin_modelo[i]==0:\n",
    "            falso_positivo = falso_positivo+1\n",
    "        else:\n",
    "            falso_negativo = falso_negativo+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6d416236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 22 9 5\n"
     ]
    }
   ],
   "source": [
    "print(verd_positivo, verd_negativo, falso_positivo, falso_negativo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590ad33a",
   "metadata": {},
   "source": [
    "## Estime la estructura del modelo usando el método por puntajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "949be6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b817e6227574ae286e1e298088dd228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num']\n",
      "[('age', 'chol'), ('sex', 'chol'), ('fbs', 'thalach'), ('fbs', 'ca'), ('fbs', 'thal'), ('restecg', 'trestbps'), ('restecg', 'thal'), ('restecg', 'age'), ('thalach', 'chol'), ('exang', 'cp'), ('exang', 'thalach'), ('exang', 'thal'), ('exang', 'oldpeak'), ('oldpeak', 'thalach'), ('oldpeak', 'slope'), ('slope', 'chol'), ('ca', 'num'), ('thal', 'oldpeak'), ('thal', 'trestbps'), ('thal', 'sex'), ('num', 'thal'), ('num', 'exang')]\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.estimators import HillClimbSearch\n",
    "from pgmpy.estimators import K2Score\n",
    "\n",
    "scoring_method = K2Score(data=datos_prueba)\n",
    "esth = HillClimbSearch(data=datos_prueba)\n",
    "estimated_modelK2 = esth.estimate(\n",
    "    scoring_method=scoring_method, max_indegree=4, max_iter=int(1e4)\n",
    ")\n",
    "print(estimated_modelK2)\n",
    "print(estimated_modelK2.nodes())\n",
    "print(estimated_modelK2.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "62263ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-760.8422067863243\n"
     ]
    }
   ],
   "source": [
    "print(scoring_method.score(estimated_modelK2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e6427a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num']\n",
      "[('age', 'chol'), ('sex', 'chol'), ('fbs', 'thalach'), ('fbs', 'ca'), ('fbs', 'thal'), ('restecg', 'trestbps'), ('restecg', 'thal'), ('restecg', 'age'), ('thalach', 'chol'), ('exang', 'cp'), ('exang', 'thalach'), ('exang', 'thal'), ('exang', 'oldpeak'), ('oldpeak', 'thalach'), ('oldpeak', 'slope'), ('slope', 'chol'), ('ca', 'num'), ('thal', 'oldpeak'), ('thal', 'trestbps'), ('thal', 'sex'), ('num', 'thal'), ('num', 'exang')]\n"
     ]
    }
   ],
   "source": [
    "estimated_modelK2 = BayesianNetwork(estimated_modelK2)\n",
    "estimated_modelK2.fit(data=datos_prueba, estimator = MaximumLikelihoodEstimator) \n",
    "\n",
    "print(estimated_modelK2)\n",
    "print(estimated_modelK2.nodes())\n",
    "print(estimated_modelK2.edges())\n",
    "\n",
    "#for i in estimated_modelK2.nodes():\n",
    "    #print(estimated_modelK2.get_cpds(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dede34d1",
   "metadata": {},
   "source": [
    "Se imprime el resultado del puntaje obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "198622a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-760.8422067863244\n"
     ]
    }
   ],
   "source": [
    "print(scoring_method.score(estimated_modelK2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "260c5af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  sex   cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "237  2.0  1.0  2.0       1.0   2.0  0.0      0.0      3.0    0.0      1.0   \n",
      "238  2.0  0.0  2.0       2.0   3.0  0.0      0.0      4.0    0.0      1.0   \n",
      "239  2.0  0.0  4.0       2.0   3.0  0.0      0.0      4.0    0.0      1.0   \n",
      "240  4.0  1.0  1.0       2.0   2.0  0.0      0.0      3.0    0.0      3.0   \n",
      "241  3.0  0.0  3.0       1.0   1.0  1.0      0.0      1.0    0.0      1.0   \n",
      "\n",
      "     slope   ca  thal  num  \n",
      "237    1.0  0.0   3.0    0  \n",
      "238    1.0  0.0   3.0    0  \n",
      "239    1.0  0.0   3.0    0  \n",
      "240    2.0  2.0   3.0    1  \n",
      "241    1.0  0.0   3.0    0  \n"
     ]
    }
   ],
   "source": [
    "# Crear una lista vacía para contener las variables del modelo\n",
    "variables_modeloK2 = []\n",
    "\n",
    "# Recorrer cada variable del modelo y agregarla a la lista si está presente en la base de datos original\n",
    "for nodo in estimated_modelK2.nodes():\n",
    "    if nodo in datos_prueba.columns:\n",
    "        variables_modeloK2.append(datos_prueba[nodo])\n",
    "\n",
    "# Concatenar todas las variables en una sola base de datos\n",
    "nueva_baseK2 = pd.concat(variables_modeloK2, axis=1)\n",
    "print(nueva_baseK2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f7c595ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un objeto de inferencia basado en el modelo entrenado\n",
    "inferK2 = VariableElimination(estimated_modelK2)\n",
    "bin_modeloK2 = []\n",
    "\n",
    "# Calcular las predicciones para cada fila en los datos de prueba\n",
    "for i in (nueva_baseK2.index):\n",
    "    evidenceK2 = nueva_baseK2.loc[i].to_dict()\n",
    "    evidenceK2.pop('num', None)  # Elimina la clave 'num' del diccionario si está presente\n",
    "    prediccionK2 = inferK2.query(['num'], evidence=evidenceK2)\n",
    "    #print(f'Predicción para la fila {i}: {prediccionK2.values}')\n",
    "\n",
    "    \n",
    "    posicion = -1\n",
    "    probabilidad = -1\n",
    "    for j in range(0,2):\n",
    "        if prediccionK2.values[estimated_modelK2.get_cpds(\"num\").state_names[\"num\"].index(j)]>probabilidad:\n",
    "            probabilidad = prediccionK2.values[estimated_modelK2.get_cpds(\"num\").state_names[\"num\"].index(j)]\n",
    "            posicion = j\n",
    "    \n",
    "    if posicion == 0:\n",
    "        bin_modeloK2.append(0)\n",
    "    else:\n",
    "        bin_modeloK2.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1a63dc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(bin_modeloK2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "546c6b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "verd_positivo = 0\n",
    "verd_negativo = 0\n",
    "falso_positivo = 0\n",
    "falso_negativo = 0\n",
    "\n",
    "#contar el número de verdaderos positivos y negativos            \n",
    "for i in range(len(nueva_baseK2)):\n",
    "    if bin_test[i]==bin_modeloK2[i]:\n",
    "        if bin_modeloK2[i]==0:\n",
    "            verd_positivo = verd_positivo+1\n",
    "        else:\n",
    "            verd_negativo = verd_negativo+1\n",
    "    else:\n",
    "        if bin_modeloK2[i]==0:\n",
    "            falso_positivo = falso_positivo+1\n",
    "        else:\n",
    "            falso_negativo = falso_negativo+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2f44e04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 29 2 4\n"
     ]
    }
   ],
   "source": [
    "print(verd_positivo, verd_negativo, falso_positivo, falso_negativo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee71826f",
   "metadata": {},
   "source": [
    "### El procedimiento anterior usando el punta BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1bec6985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a4052e1431416eb592f072ee78b119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num']\n",
      "[('exang', 'cp'), ('exang', 'oldpeak'), ('exang', 'slope'), ('oldpeak', 'thalach'), ('thal', 'num'), ('thal', 'sex'), ('num', 'ca'), ('num', 'exang')]\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.estimators import BicScore\n",
    "\n",
    "scoring_method = BicScore(data=datos_prueba)\n",
    "esth = HillClimbSearch(data=datos_prueba)\n",
    "estimated_modelBic = esth.estimate(\n",
    "    scoring_method=scoring_method, max_indegree=4, max_iter=int(1e4)\n",
    "\n",
    ")\n",
    "print(estimated_modelBic)\n",
    "print(estimated_modelBic.nodes())\n",
    "print(estimated_modelBic.edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be17f1c",
   "metadata": {},
   "source": [
    "Se imprime el resultado del puntaje obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1802f76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-805.8697998114878\n"
     ]
    }
   ],
   "source": [
    "print(scoring_method.score(estimated_modelBic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "64f5b6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num']\n",
      "[('exang', 'cp'), ('exang', 'oldpeak'), ('exang', 'slope'), ('oldpeak', 'thalach'), ('thal', 'num'), ('thal', 'sex'), ('num', 'ca'), ('num', 'exang')]\n"
     ]
    }
   ],
   "source": [
    "estimated_modelBic = BayesianNetwork(estimated_modelBic)\n",
    "estimated_modelBic.fit(data=datos_prueba, estimator = MaximumLikelihoodEstimator) \n",
    "\n",
    "print(estimated_modelBic)\n",
    "print(estimated_modelBic.nodes())\n",
    "print(estimated_modelBic.edges())\n",
    "\n",
    "#for i in estimated_modelK2.nodes():\n",
    "    #print(estimated_modelK2.get_cpds(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "287af5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-805.8697998114878\n"
     ]
    }
   ],
   "source": [
    "print(scoring_method.score(estimated_modelBic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c31227fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  sex   cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "237  2.0  1.0  2.0       1.0   2.0  0.0      0.0      3.0    0.0      1.0   \n",
      "238  2.0  0.0  2.0       2.0   3.0  0.0      0.0      4.0    0.0      1.0   \n",
      "239  2.0  0.0  4.0       2.0   3.0  0.0      0.0      4.0    0.0      1.0   \n",
      "240  4.0  1.0  1.0       2.0   2.0  0.0      0.0      3.0    0.0      3.0   \n",
      "241  3.0  0.0  3.0       1.0   1.0  1.0      0.0      1.0    0.0      1.0   \n",
      "\n",
      "     slope   ca  thal  num  \n",
      "237    1.0  0.0   3.0    0  \n",
      "238    1.0  0.0   3.0    0  \n",
      "239    1.0  0.0   3.0    0  \n",
      "240    2.0  2.0   3.0    1  \n",
      "241    1.0  0.0   3.0    0  \n"
     ]
    }
   ],
   "source": [
    "# Crear una lista vacía para contener las variables del modelo\n",
    "variables_modeloBic = []\n",
    "\n",
    "# Recorrer cada variable del modelo y agregarla a la lista si está presente en la base de datos original\n",
    "for nodo in estimated_modelBic.nodes():\n",
    "    if nodo in datos_prueba.columns:\n",
    "        variables_modeloBic.append(datos_prueba[nodo])\n",
    "\n",
    "# Concatenar todas las variables en una sola base de datos\n",
    "nueva_baseBic = pd.concat(variables_modeloBic, axis=1)\n",
    "print(nueva_baseBic.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1d1d1b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear un objeto de inferencia basado en el modelo entrenado\n",
    "inferBic = VariableElimination(estimated_modelBic)\n",
    "bin_modeloBic = []\n",
    "\n",
    "# Calcular las predicciones para cada fila en los datos de prueba\n",
    "for i in (nueva_baseBic.index):\n",
    "    evidenceBic = nueva_baseBic.loc[i].to_dict()\n",
    "    #print(evidenceBic)\n",
    "    evidenceBic.pop('num', None)  # Elimina la clave 'num' del diccionario si está presente\n",
    "    prediccionBic = inferBic.query(['num'], evidence=evidenceBic)\n",
    "    #print(f'Predicción para la fila {i}: {prediccionBic.values}')\n",
    "\n",
    "    \n",
    "    posicion = -1\n",
    "    probabilidad = -1\n",
    "    for j in range(0,2):\n",
    "        if prediccionBic.values[estimated_modelBic.get_cpds(\"num\").state_names[\"num\"].index(j)]>probabilidad:\n",
    "            probabilidad = prediccionBic.values[estimated_modelBic.get_cpds(\"num\").state_names[\"num\"].index(j)]\n",
    "            posicion = j\n",
    "    \n",
    "    if posicion == 0:\n",
    "        bin_modeloBic.append(0)\n",
    "    else:\n",
    "        bin_modeloBic.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1708afda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bin_modeloBic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a0db7571",
   "metadata": {},
   "outputs": [],
   "source": [
    "verd_positivo = 0\n",
    "verd_negativo = 0\n",
    "falso_positivo = 0\n",
    "falso_negativo = 0\n",
    "\n",
    "#contar el número de verdaderos positivos y negativos            \n",
    "for i in range(len(nueva_baseBic)):\n",
    "    if bin_test[i]==bin_modeloBic[i]:\n",
    "        if bin_modeloBic[i]==0:\n",
    "            verd_positivo = verd_positivo+1\n",
    "        else:\n",
    "            verd_negativo = verd_negativo+1\n",
    "    else:\n",
    "        if bin_modeloBic[i]==0:\n",
    "            falso_positivo = falso_positivo+1\n",
    "        else:\n",
    "            falso_negativo = falso_negativo+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6a858d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 27 4 5\n"
     ]
    }
   ],
   "source": [
    "print(verd_positivo, verd_negativo, falso_positivo, falso_negativo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e015ada7",
   "metadata": {},
   "source": [
    "## El mejor modelo por método de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b498cfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3719.4516965632365\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bic_score2 = BicScore(data=datos_train).score(estimated_modelK2)\n",
    "print(bic_score2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
